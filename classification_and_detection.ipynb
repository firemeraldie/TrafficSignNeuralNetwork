{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Завантаження бібліотек"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T13:32:59.862900Z",
     "end_time": "2023-05-07T13:33:02.261563Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Підготовка і завантаження моделі"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (32, 32)\n",
      "Classificator model loaded\n",
      "Mean image shape:  (3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data_path = './DetectionData'\n",
    "preprocessed_path = data_path + \"/traffic-signs-preprocessed\"\n",
    "in_yolo_format_path = data_path + \"/traffic-signs-dataset-in-yolo-format\"\n",
    "signs_detector_path = data_path + \"/trained-traffic-signs-detector-based-on-yolo-v3\"\n",
    "\n",
    "cls_model = load_model(\"./sign_classifier_v1m4.h5\")\n",
    "input_shape = cls_model.layers[0].input_shape[1:3]\n",
    "print(\"Input shape: \", input_shape)\n",
    "\n",
    "class_labels = pd.read_csv(\"./ClassificationDataSet/Labels.csv\")\n",
    "\n",
    "with open(preprocessed_path + '/mean_image_rgb.pickle', 'rb') as f:\n",
    "    mean = pickle.load(f, encoding='latin1')\n",
    "\n",
    "print(\"Classificator model loaded\")\n",
    "print(\"Mean image shape: \", mean['mean_image_rgb'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T13:48:05.227882Z",
     "end_time": "2023-05-07T13:48:05.369223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection model loaded\n"
     ]
    }
   ],
   "source": [
    "path_to_weights = signs_detector_path + \"/yolov3_ts_train_5000.weights\"\n",
    "path_to_cfg = in_yolo_format_path + \"/yolov3_ts_test.cfg\"\n",
    "\n",
    "det_model = cv2.dnn.readNetFromDarknet(path_to_cfg, path_to_weights)\n",
    "det_model.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "det_model.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL_FP16)\n",
    "\n",
    "print(\"Detection model loaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T13:48:10.250010Z",
     "end_time": "2023-05-07T13:48:10.612228Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "source": [
    "layers_all = det_model.getLayerNames()\n",
    "layers_names_output = [layers_all[i - 1] for i in det_model.getUnconnectedOutLayers()]\n",
    "print(layers_names_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T13:48:11.097253Z",
     "end_time": "2023-05-07T13:48:11.113284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "probability_minimum = 0.1\n",
    "threshold = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T13:48:11.670440Z",
     "end_time": "2023-05-07T13:48:11.676443Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Завантаження зображення"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (637, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"./MyTestData/Detection/full_photo2.jpg\")\n",
    "\n",
    "h, w = image.shape[:2]\n",
    "print(\"Image shape: \", image.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T14:22:42.643045Z",
     "end_time": "2023-05-07T14:22:42.669063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects Detection took 0.85267 seconds\n"
     ]
    }
   ],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "det_model.setInput(blob)\n",
    "start = time.time()\n",
    "output_from_detector = det_model.forward(layers_names_output)\n",
    "end = time.time()\n",
    "\n",
    "print('Objects Detection took {:.5f} seconds'.format(end - start))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T14:22:42.820165Z",
     "end_time": "2023-05-07T14:22:43.684357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "bounding_boxes = []\n",
    "confidences = []\n",
    "class_numbers = []\n",
    "\n",
    "# Going through all output layers after feed forward pass\n",
    "for result in output_from_detector:\n",
    "    # Going through all detections from current output layer\n",
    "    for detection in result:\n",
    "        score = detection[5:]\n",
    "        class_current = np.argmax(score)\n",
    "        confidence_current = score[class_current]\n",
    "\n",
    "        # Eliminating weak predictions with minimum probability\n",
    "        if confidence_current > probability_minimum:\n",
    "            box_current = detection[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "            # Now, from YOLO data format, convert it to format that is used by OpenCV\n",
    "            x_center, y_center, box_width, box_height = box_current.astype('int')\n",
    "            box_width *= 1.1\n",
    "            box_height *= 1.1\n",
    "            x_min = int(x_center - (box_width / 2))\n",
    "            y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "            # Adding results into prepared lists\n",
    "            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "            confidences.append(float(confidence_current))\n",
    "            class_numbers.append(class_current)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T14:22:43.688354Z",
     "end_time": "2023-05-07T14:22:43.733239Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Detected:  No entry: 1.0\n"
     ]
    }
   ],
   "source": [
    "results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
    "\n",
    "if len(results) > 0:\n",
    "    for i in results.flatten():\n",
    "        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "        # cut detected sign\n",
    "        cut_sign = image[y_min:y_min + box_height, x_min:x_min + box_width]\n",
    "\n",
    "        blob_sign = cv2.dnn.blobFromImage(cut_sign, 1 / 255.0, input_shape, swapRB=False, crop=False)\n",
    "        blob_sign[0] -= mean['mean_image_rgb']\n",
    "        blob_sign = blob_sign.transpose(0, 2, 3, 1)\n",
    "\n",
    "        # classify sign\n",
    "        class_predicted = cls_model.predict(blob_sign)[0]\n",
    "        inID = np.argmax(class_predicted)\n",
    "        label = class_labels.loc[inID][1] + ': ' + str(round(class_predicted[inID], 2))\n",
    "\n",
    "        colour_box_current = (255, 255, 255)\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_min + box_width, y_min + box_height), colour_box_current, 2)\n",
    "\n",
    "        text_box_current = label\n",
    "        # add shadow to text\n",
    "        (text_width, text_height) = cv2.getTextSize(text_box_current, cv2.FONT_HERSHEY_TRIPLEX, 0.7, 1)[0]\n",
    "        text_offset_x = x_min\n",
    "        text_offset_y = y_min - 5\n",
    "        box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, box_coords[0], box_coords[1], (0, 0, 0), cv2.FILLED)\n",
    "        image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "        # add text\n",
    "        cv2.putText(image, text_box_current, (x_min, y_min - 5), cv2.FONT_HERSHEY_TRIPLEX, 0.7, colour_box_current, 1, cv2.LINE_AA)\n",
    "\n",
    "        print(\"Detected: \", label)\n",
    "\n",
    "    cv2.imwrite(\"./classification_and_detection.jpg\", image)\n",
    "\n",
    "else:\n",
    "    print('No signs detected')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T14:22:43.738252Z",
     "end_time": "2023-05-07T14:22:43.821106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Detection results', image)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T14:22:44.229865Z",
     "end_time": "2023-05-07T14:22:51.575556Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
